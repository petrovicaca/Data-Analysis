# -*- coding: utf-8 -*-
"""KMeansClustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qiFm1IB1G9wkL0aSiqau_kTVUyDGPJTC
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set(style="ticks", color_codes = True)
# %matplotlib inline

url="https://raw.githubusercontent.com/hajdeger/AOP_PUB/master/kc_house_data.csv"

df= pd.read_csv(url)

df.columns

df

df=df.drop(['id'], axis=1)

df=df.drop(['date'], axis=1)

df.isnull()

df.isnull().count()

price = df.pop('price')

price

df['price'] = price

df

df.eq(0).any().any()

(df == 0).sum(axis=0)

x1=df.iloc[:,:].values

x = df.iloc[:, :-1].values
y = df.iloc[:, -1:].values

x

y

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=2019)

from sklearn.preprocessing import MinMaxScaler

scaler2 = MinMaxScaler()

scaler2.fit(x1)

scaler2.fit(X_train)

x1 = scaler2.transform(x1)

X_train = scaler2.transform(X_train)

X_test = scaler2.transform(X_test)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

scaler.fit(X_train)

X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

from sklearn.cluster import KMeans

Sum_of_squared_distances = []
K = range(1,20)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(X_train)
    Sum_of_squared_distances.append(km.inertia_)

plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()

from sklearn.metrics import silhouette_samples, silhouette_score

range_n_clusters = np.arange(2,41)

range_n_clusters

import matplotlib.cm as cm

ss=[]
for n_clusters in range_n_clusters:
  fig, ax1 = plt.subplots()
  fig.set_size_inches(18,7)
 
  ax1.set_xlim([-0.1,1])
 
  ax1.set_ylim([0, len(X_train) + (n_clusters + 1) * 10])
 
  clusterer = KMeans(n_clusters = n_clusters, random_state = 10)
  cluster_labels = clusterer.fit_predict(X_train)
 
  silhouette_avg = silhouette_score(X_train, cluster_labels)
 
  print("For n_clusters =" , n_clusters,
        "The average silhouette_score is :", silhouette_avg)
 
  #Izračunavanje skora za svaki uzorak
  sample_silhouette_values = silhouette_samples(X_train, cluster_labels)
 
  y_lower = 10
 
  for i in range(n_clusters):
    # Aggregate the silhouette scores for samples belonging to
    # cluster i, and sort them
 
    ith_cluster_silhouette_values = \
      sample_silhouette_values[cluster_labels == i]
 
    ith_cluster_silhouette_values.sort()
 
    size_cluster_i = ith_cluster_silhouette_values.shape[0]
    y_upper = y_lower + size_cluster_i
   
    color = cm.nipy_spectral(float(i) / n_clusters)
    ax1.fill_betweenx(np.arange(y_lower, y_upper),
                      0, ith_cluster_silhouette_values,
                      facecolor=color, edgecolor=color, alpha=0.7)
    ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))
 
    y_lower = y_upper + 10
 
    ax1.set_title("The silhouette plot for the various clusters.")
    ax1.set_xlabel("The silhouette coefficient values")
    ax1.set_ylabel("Cluster label")
 
    ax1.axvline(x=silhouette_avg, color="red", linestyle="--")
 
    ax1.set_yticks([])
    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])
 
    centers = clusterer.cluster_centers_
 
    plt.suptitle(("Silhouette analysis for KMeans clustering on sample data"
                  "with n_clusters = %d" % n_clusters),
                 fontsize=14, fontweight='bold')
   
plt.show()

range_n_clusters_2=np.arange(2,21)

ss=[]
for n_clusters in range_n_clusters_2:
  fig, ax1 = plt.subplots()
  fig.set_size_inches(18,7)
 
  ax1.set_xlim([-0.1,1])
 
  ax1.set_ylim([0, len(x1) + (n_clusters + 1) * 10])
 
  clusterer = KMeans(n_clusters = n_clusters, random_state = 10)
  cluster_labels = clusterer.fit_predict(x1)
 
  silhouette_avg = silhouette_score(x1, cluster_labels)
 
  print("For n_clusters =" , n_clusters,
        "The average silhouette_score is :", silhouette_avg)
 
  #Izračunavanje skora za svaki uzorak
  sample_silhouette_values = silhouette_samples(x1, cluster_labels)
 
  y_lower = 10
 
  for i in range(n_clusters):
    # Aggregate the silhouette scores for samples belonging to
    # cluster i, and sort them
 
    ith_cluster_silhouette_values = \
      sample_silhouette_values[cluster_labels == i]
 
    ith_cluster_silhouette_values.sort()
 
    size_cluster_i = ith_cluster_silhouette_values.shape[0]
    y_upper = y_lower + size_cluster_i
   
    color = cm.nipy_spectral(float(i) / n_clusters)
    ax1.fill_betweenx(np.arange(y_lower, y_upper),
                      0, ith_cluster_silhouette_values,
                      facecolor=color, edgecolor=color, alpha=0.7)
    ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))
 
    y_lower = y_upper + 10
 
    ax1.set_title("The silhouette plot for the various clusters.")
    ax1.set_xlabel("The silhouette coefficient values")
    ax1.set_ylabel("Cluster label")
 
    ax1.axvline(x=silhouette_avg, color="red", linestyle="--")
 
    ax1.set_yticks([])
    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])
 
    centers = clusterer.cluster_centers_
 
    plt.suptitle(("Silhouette analysis for KMeans clustering on sample data"
                  "with n_clusters = %d" % n_clusters),
                 fontsize=14, fontweight='bold')
   
plt.show()

from sklearn.neighbors import KNeighborsClassifier

classifier = KNeighborsClassifier(n_neighbors=35)
classifier.fit(X_train, y_train)

y_pred=classifier.predict(X_test)

y_pred

print([y_test,y_pred])



km1 = KMeans(n_clusters=10)
km1 = km1.fit(x1)

y=km1.predict(x1)

y

x1.shape

from sklearn.manifold import TSNE

tsne = TSNE(n_components=2,learning_rate=300,perplexity = 30,early_exaggeration = 12,init = 'random',  random_state=2019)
X_tsne = tsne.fit_transform(x1)

plt.figure(figsize=(12,12))

plt.scatter(X_tsne[y==0, 0], X_tsne[y==0, 1], color='red', alpha=0.5,label='0')
plt.scatter(X_tsne[y==1, 0], X_tsne[y==1, 1], color='blue', alpha=0.5,label='1')
plt.scatter(X_tsne[y==2, 0], X_tsne[y==2, 1], color='green', alpha=0.5,label='2')
plt.scatter(X_tsne[y==3, 0], X_tsne[y==3, 1], color='black', alpha=0.5,label='3')
plt.scatter(X_tsne[y==4, 0], X_tsne[y==4, 1], color='khaki', alpha=0.5,label='4')
plt.scatter(X_tsne[y==5, 0], X_tsne[y==5, 1], color='yellow', alpha=0.5,label='5')
plt.scatter(X_tsne[y==6, 0], X_tsne[y==6, 1], color='turquoise', alpha=0.5,label='6')
plt.scatter(X_tsne[y==7, 0], X_tsne[y==7, 1], color='pink', alpha=0.5,label='7')
plt.scatter(X_tsne[y==8, 0], X_tsne[y==8, 1], color='moccasin', alpha=0.5,label='8')
plt.scatter(X_tsne[y==9, 0], X_tsne[y==9, 1], color='olive', alpha=0.5,label='9')
plt.title("TSNE")
plt.ylabel('Koordinata Y')
plt.xlabel('Koordinata X')
plt.legend()
plt.show()

df

df['y'] = y

np.unique(y)

train_summary = df.groupby(by='y').mean()

train_summary

